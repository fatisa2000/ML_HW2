{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatisa2000/ML_HW2/blob/main/Question2_n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "un_07izr0mCO"
      },
      "source": [
        "<h1 align=\"center\">An Introduction to Machine Learning - 25737</h1>\n",
        "<h4 align=\"center\">Dr. Sajjad Amini</h4>\n",
        "<h4 align=\"center\">Sharif University of Technology, Spring 2023</h4>\n",
        "\n",
        "**Student Name**:\n",
        "\n",
        "**Student ID**:\n",
        "\n",
        "# Effect of Overfitting\n",
        "\n",
        "In this exercise, we want to examine the effect of **overfitting**. As you learned in class, using too many features in training can result in a model with very low loss on the training set but high loss on the validation and test set. For this purpose, we have prepared a dataset in the `q2-train.npy`, `q2-valid.npy`, and `q2-test.npy` files for you. We know that `y` is a polynomial function of `x` in this dataset, meaning that \n",
        "\n",
        "$$\n",
        "y = \\sum_{i=0}^{k}a_ix^i\n",
        "$$\n",
        "\n",
        "However, we do not know the exact value of `k`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcSNUeqT158e"
      },
      "source": [
        "## Importing Libraries\n",
        "\n",
        "First, we import the necessary libraries for this assignment. Please note that you should only use these libraries and no other libraries are acceptable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UitW8b0J0jBa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1x7BaU22F4k"
      },
      "source": [
        "## Reading Data and Preprocessing\n",
        "\n",
        "In this part of the assignment, you should read data from the `.npy` files. The data in `q2-train.npy` file is your training set and should be stored in the `X_train` and `Y_train` variables. Similarly, the data in `q2-valid.npy` file is your validation set, and the data in `q2-test.npy` file is your test set, which should be stored in `X_val`, `Y_val`, `X_test`, and `Y_test` respectively. You can use the `np.load` function to read the `.npy` files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dDMeq10G2m0U"
      },
      "outputs": [],
      "source": [
        "X_train, Y_train, X_val, Y_val, X_test, Y_test = None, None, None, None, None, None\n",
        "\n",
        "### START CODE HERE ###\n",
        "x=np.load('q2-test.npy')\n",
        "x1=np.load('q2-train.npy')\n",
        "x2=np.load('q2-valid.npy')\n",
        "X_test=x[:,0]\n",
        "Y_test=x[:,1]\n",
        "X_train=x1[:,0]\n",
        "Y_train=x1[:,1]\n",
        "X_val=x2[:,0]\n",
        "Y_val=x2[:,1]\n",
        "### END CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyXpEfEa3Gw-"
      },
      "source": [
        "To find the best value of `k`, we want to change `k` from 1 to 12 and examine its effect on the validation set, and then choose the right value of `k`. For this purpose, we need to create a matrix with columns equal to $x^0$, $x^1$, $x^2$, ..., $x^k$ for every value of `k`. You can complete the following function to do this job. The function takes an $m \\times 1$ vector `X` containing values of input `x` and returns an $m \\times (k+1)$ matrix that has the properties mentioned above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DXw2tPO84Ksp"
      },
      "outputs": [],
      "source": [
        "def create_matrix(X,k):\n",
        "  '''\n",
        "  X: an m by 1 array \n",
        "  '''\n",
        "  new_X = []\n",
        "  m=np.size(X)\n",
        "  ### START CODE HERE ###\n",
        "  for i in range(m):\n",
        "    a=[]\n",
        "    result=1\n",
        "    for exponent in range(k+1):\n",
        "      result*=X[i]\n",
        "      a.append(result)\n",
        "    new_X.append(a)\n",
        "\n",
        "  ### END CODE HERE ###\n",
        "  return new_X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCTuye7C5Aq3"
      },
      "source": [
        "## Validate Model\n",
        "\n",
        "Now, we want to train our model for every value of `k`. You can use any of the methods that we used in **Question 1** (gradient descent or direct calculation) for this purpose. The following function trains our model on the training set for a given value of `k`, and then returns the loss on the training set and validation set, as well as the weight vector `w`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "9lfWITgf7yQH"
      },
      "outputs": [],
      "source": [
        "# If you need any other function for training write it here\n",
        "# (like gradient descent or anything else)\n",
        "\n",
        "def gradient_descent(X, Y, alpha, num_iter):\n",
        "  '''\n",
        "  X: an m by (n+1) matrix which includes inputs\n",
        "  Y: an m by 1 vector which includes heating loads\n",
        "  alpha: learning rate\n",
        "  num_iter: number of iterations of the algorithm\n",
        "  '''\n",
        "  m, n = X.shape\n",
        "  w = None\n",
        "  loss_history=[]\n",
        "  ### START CODE HERE ###\n",
        "  w=np.random.rand(n)\n",
        "  for i in range(num_iter):\n",
        "    yy=np.dot(X,w)\n",
        "    yy=np.reshape(yy,(m,1))\n",
        "    i=np.reshape(((1/m)*0.01*(np.dot(l.T,(yy-g)))),(n))\n",
        "    w=w-i\n",
        "    loss=(1/2*m)*np.sum(np.square(yy-Y))\n",
        "    loss_history.append(loss)\n",
        "\n",
        "  ### END CODE HERE ###\n",
        "  return w, loss_history\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(X, Y, w):\n",
        "  '''\n",
        "  X: an m by (n+1) matrix which includes inputs\n",
        "  Y: an m by 1 vector which includes heating loads\n",
        "  w: an (n+1) by 1 weight vector\n",
        "  '''\n",
        "  m, n = X.shape\n",
        "  loss = None\n",
        "  ### START CODE HERE ###\n",
        "  yy=np.dot(X,w)\n",
        "  loss=np.sum(np.dot((yy-Y).T,(yy-Y)))/np.size(yy)\n",
        "  ### END CODE HERE ###\n",
        "  return loss"
      ],
      "metadata": {
        "id": "mc7c29CeQNwI"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "JaIs631q508z"
      },
      "outputs": [],
      "source": [
        "def train(X_train, Y_train, X_val, Y_val, k):\n",
        "  '''\n",
        "  X_train: an m_train by 1 vector contains training points\n",
        "  Y_train: an m_train by 1 vector contains training values\n",
        "  X_val: an m_val by 1 vector contains validation points\n",
        "  Y_val: an m_val by 1 vector contains validation values\n",
        "  k: degree of polynomial\n",
        "  '''\n",
        "  w, loss_train, loss_val = None, None\n",
        "  ### START CODE HERE ###\n",
        "  w,loss_train=gradient_descent(X_train, Y_train,0.01,1000)\n",
        "  loss_val=loss(X_val,Y_val,w)\n",
        "  \n",
        "  ### END CODE HERE ###\n",
        "  return w, loss_train, loss_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAsZfxCu6YEf"
      },
      "source": [
        "In the cell below, you can change the value of `k` between 1 and 12 and plot the loss on the training and validation set as a function of `k` in the same plot.\n",
        "\n",
        "**Question**: Discuss about the effect of $k$.\n",
        "\n",
        "**Answer**:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the higher the degree of the polynomial, the higher the interpolation precision on training data and the lower the performance on test data.\n"
      ],
      "metadata": {
        "id": "MQq4EJycRRga"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "knUTXtOv66Wx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "97897e59-9cad-460b-9d67-65d9d2991a58"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-9caf82ea8c32>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mxt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxt_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mxv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxv_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myt_n\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myv_n\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m### END CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-15094c2e165a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(X_train, Y_train, X_val, Y_val, k)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdegree\u001b[0m \u001b[0mof\u001b[0m \u001b[0mpolynomial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   '''\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0;31m### START CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
          ]
        }
      ],
      "source": [
        "### START CODE HERE ###\n",
        "xn=create_matrix(X_train,2)\n",
        "x_m=np.mean(xn)\n",
        "x_sigma=np.std(xn)\n",
        "xv_m=np.mean(X_val)\n",
        "xv_sigma=np.std(X_val)\n",
        "y_v=np.mean(Y_val)\n",
        "yv_sigma=np.std(Y_train)\n",
        "y_m=np.mean(Y_train)\n",
        "y_sigma=np.std(Y_train)\n",
        "xt_n=(xn-x_m)/x_sigma\n",
        "xv_n=(X_val-xv_m)/xv_sigma\n",
        "yt_n=(Y_train-y_m)/y_sigma\n",
        "yv_n=(Y_val-y_v)/yv_sigma\n",
        "\n",
        "m=xt_n.shape[0]\n",
        "m1=xv_n.shape[0]\n",
        "xt=np.c_[np.ones((m,1)),xt_n]\n",
        "xv=np.c_[np.ones((m1,1)),xv_n]\n",
        "print(train(xt,yt_n,xv,yv_n,10))\n",
        "### END CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0M1d2Ez7JLJ"
      },
      "source": [
        "## Evaluating Model\n",
        "\n",
        "In the cell below find the loss of your best model on the test set.\n",
        "\n",
        "**Question**: Why we need test set?\n",
        "\n",
        "**Answer**:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the test set is a separate set of data used to test the model after completing the training. It provides an unbiased final model performance metric in terms of accuracy, precision, etc. To put it simply, it answers the question of \"How well does the model perform?"
      ],
      "metadata": {
        "id": "aBxnIXUUetNJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ex1P5H0A7emE"
      },
      "outputs": [],
      "source": [
        "### START CODE HERE ###\n",
        "\n",
        "### END CODE HERE ###"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}